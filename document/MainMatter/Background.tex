\chapter{Estado del Arte}\label{chapter:state-of-the-art}

\section{Modelado de Optimización}
El análisis de la literatura revela que la creación de modelos de optimización a partir de lenguaje natural se centra en dos desafíos conceptuales principales.
El primero es la Extracción Semántica y de Características, que implica la identificación precisa de la información y las restricciones a partir de la descripción textual.
El segundo es la Selección del Paradigma de Modelación, que se refiere a la elección de la estructura y el tipo de representación formal (matemática) del problema.
Ambos pilares serán abordados detalladamente en esta sección, utilizando los marcos teóricos de la investigación relacionada.


\subsection{Enfoques de Modelado}
La competencia \textit{NL4Opt} (\cite{ramamonjison2023nl4optcompetitionformulatingoptimization}) fue creada con el objetivo de explorar diferentes técnicas para modelar matemáticamente un problema de optimización lineal a partir de una descripción en lenguaje natural.
Para realizar este proceso, en esta competencia se propone una metodología basada en dos sub-tareas principales. La primera de ellas es \textit{Named Entity Recognition} (NER), la cual consiste en etiquetar las entidades fundamentales en la descripción del problema: restricciones, variables, objetivos, etc.
La segunda sub-tarea es modelar el problema a partir del texto etiquetado, usando una representación intermedia (IR) basada en etiquetas \textit{XML}.
Para la realización de ambas tareas se propone el uso de modelos como \textit{BERT} (\cite{devlin2019bert}) y \textit{XLM-R} (\cite{conneau2020xlmr}).



En los trabajos presentados por~\cite{ning2023novelapproachautoformulationoptimization} y~\cite{highlightingnamedentities} se sigue la metodología propuesta en \textit{NL4Opt} para la modelación a partir de lenguaje natural, aunque el segundo artículo solo se enfoca en la segunda sub-tarea.
En el trabajo de~\cite{ning2023novelapproachautoformulationoptimization} se utiliza XLM-R como modelo base para el reconocimiento y etiquetado de entidades. A este se le aplica además ajuste fino (\textit{fine-tuning}) adoptando un entrenamiento adversarial para mejorar la capacidad de generalización del modelo.
Los autores también presentan una serie de reglas para realizar un post-procesamiento del texto etiquetado.
Para la segunda sub-tarea ambos trabajos emplean diferentes versiones de \textit{BERT} para transformar el texto etiquetado en la representación intermedia en un solo paso.
Ambos trabajos lograron buenos resultados al evaluarse de forma \textit{end to end} en el conjunto de problemas presentados en \textit{NL4Opt}.
Sin embargo, estos resultados contrastan con los publicados por~\cite{ramamonjison2023nl4optcompetitionformulatingoptimization} quienes realizan una comparación de la eficacia entre las mejores soluciones siguiendo la metodología presentada en la competencia y las capacidades de un gran modelo de languaje como \textit{ChatGPT} para resolver la misma tarea.
Se utilizó \textit{ChatGPT-3.5-turbo} y se llegó a la conclusión de que este modelo superó a dichas soluciones sin necesidad de \textit{fine-tuning} ni un etiquetado previo de entidades.



%% Prompting

Analizando la literatua estudiada posterior a los trabajos antes mencionados, es posible deducir que la metodología propuesta en \textit{NL4Opt} resultó mucho menos eficaz que otros enfoques basados en grandes modelos de lenguaje.
Es posible que tanto las conclusiones presentadas por \cite{ramamonjison2023nl4optcompetitionformulatingoptimization}, así como la acelerada evolución de las capacidades de los LLM en los últimos años (\cite{chen2025surveyscalinglargelanguage}) hayan contribuido a descontinuar la metodología presentada en \textit{NL4Opt} y a utilizar grandes modelos de lenguaje.

En general la mayoría de los estudios y artículos consultados optan por utilizar LLMs para la modelación a partir de lenguaje natural.
Sin embargo, las estrategias empleadas para inducir al LLM a realizar esta tarea varían considerablemente.
A continuación se abordan los enfoques principales seguidos en la literatura consultada.


Uno de estos enfoques es utilizar técnicas de \textit{prompt engineering} para que el LLM genere el modelo directamente a partir de la descripción del problema.
Algunos trabajos simplemente utilizan instrucciones directas y sencillas, para instruir al modelo a generar código en lenguajes de modelado, como \textit{MiniZinc} o \textit{CPMpy}, a partir de la descripción en lenguaje natural (\cite{almonacid2023automaticoptimisationmodelgenerator}, \cite{tsouros2023holygrail20natural}).
Otros utilizan un enfoque por etapas, donde primero el LLM clasifica las variables y restricciones, y luego se genera una modelación matemática (\cite{li2023synthesizingmixedintegerlinearprogramming}).

En trabajos como \textit{OptiMUS} presentados por \cite{ahmaditeshnizi2025optimus03usinglargelanguage} se utilizan y exploran algunas ideas interesantes:
\begin{itemize}
    \item Se instruye al LLM a extraer la información relevante por partes: se extraen primero los parámetros y variables y luego las restricciones y objetivo.
    \item No se limitan a identificar y extraer variables, también se le encomienda al modelo identificar dominios, tipos e información contextual.
    \item Se incluyen en el \textit{prompt} un conjunto de ejemplos de salidas esperadas, facilitando al LLM devolver la estructura requerida de la modelación.
\end{itemize}

Otra característica que presenta \textit{OptiMUS} es el uso de \textit{reflective prompting} (\cite{shinn2023reflexionlanguageagentsverbal}) para inducir al modelo a analizar su salida reflexivamente.
Facilitando al LLMs identificar y corregir sus propios errores en la modelación del problema. Se concluye que el uso de \textit{reflection} reduce significativamente los errores de modelación.

En \textit{OptiMUS} además se experimenta con el uso de \textit{Retrieval Augmented Generation} (RAG) (\cite{lewis2021retrievalaugmentedgenerationknowledgeintensivenlp}) con el objetivo de enriquecer el \textit{prompt} con información y ejemplos relevante o similares a la tarea a realizar, que se buscan y extraen de una base de datos preparada.
Prueban el uso de RAG en dos fases de la modelación: la extracción de las cláusulas (restricciones y objetivos), y durante la modelación de las mismas.
De esta manera evaluan la influencia de esta técnica en la capacidad de modelar correctamente las cláusulas del problema, al encontrar modelaciones similares e incluirlas en el \textit{prompt}.
Sin embargo, en los resultados obtenidos con el uso de RAG se muestran inconsistencias en la eficiencia del LLM para modelar el problema, por tanto se desestimó su uso en la solución final de \textit{OptiMUS}.


Por su parte, \cite{xiao2024chainofexperts} en su trabajo \textit{Chain-of-Experts} (CoE) proponen una solución basada en una estructura cooperativa multi-agente.
Este enfoque descompone la tarea de modelado en responsabilidades granulares, las cuales se asignan a un conjunto de agentes con conocimientos de dominio específicos, llamados “expertos”.
Similar a \textit{OptiMUS}, en CoE se extrae la información relevante del problema por partes, para ello se designan varios expertos a esta tarea, cada uno con el objetivo de extraer una característica esencial del problema (variables, parámetros, restricciones, etc).
En este trabajo además se utilizan técnicas de \textit{prompting} como \textit{chain of thought} (CoT) (\cite{wei2023chainofthoughtpromptingelicitsreasoning}) para potenciar las capacidades de razonamiento de los “expertos”, mejorando así sus desempeños en las tareas de extracción y modelación.
Este estudio aporta una comparativa entre la eficacia del enfoque multiagente propuesto frente a una estrategia basada en emplear diferentes técnicas de \textit{prompting} como \textit{chain of thought}, \textit{tree of thought}, \textit{reflection} en un único modelo de lenguaje.

Es importante destacar que todos los trabajos antes mencionados solo utilizan como modelos base a ChatGPT-3.5-turbo, ChatGPT-4 o ChatGPT-4o. Ya que fueron publicados antes de la llegada de los llamados “modelos razonadores” como la serie \textit{o} de \textit{OpenAI} o los últimos modelos de \textit{Gemini}.


El enfoque alternativo a usar técnicas de \textit{prompting}, es aplicar \textit{fine-tuning} a grandes modelos de lenguaje de código abierto, con el próposito de especializarlos en transformar lenguaje natural en modelos de optimización.
En el trabajo propuesto por \cite{huang2025orlmcustomizableframeworktraining} se presenta \textit{ORLM}, una herramienta que modela problemas de optimización usando modelos de código abierto de tamaño reducido, entrenados con una gran cantidad de datos.
Se diseña y presenta un método llamado \textit{OR-instruct}, con el objetivo de generar una gran cantidad de datos necesarios para el entrenamiento de los modelos. Se parte de un número reducido de problemas y se emplean diferentes técnicas de \textit{data augmentation} y validación para generar nuevos problemas, logrando generar 30000 problemas de optimización para el entrenamiento de los modelos.
Se experimenta con el uso de diferentes modelos como: Mistral-7B, Deepseek-Math-7B-Base y LLaMA-3-8B AI, donde todos alcanzan un rendimiento similar.
En este estudio también se compara la efectividad de esta propuesta con respecto a otras soluciones mencionadas anteriormente. Se concluyó que \textit{ORLM} supera por un amplio margen a técnicas de \textit{prompting} aplicadas sobre un LLM, y además logra una ligera mejora sobre el desempeño de trabajos como \textit{Chain-of-Experts} y \textit{OptiMUS}.


\cite{jiang2025llmopt} emplean esta misma estrategia para modelar problemas de optimización. Se opta por usar Qwen1.5-14B (\cite{bai2023qwentechnicalreport}), un modelo ligeramente más grande a los empleados en \textit{ORLM}.
Al igual que en \textit{ORLM} se realiza una comparación con los métodos basados en \textit{prompts}, llegando a una misma conclusión. Los resultados de este trabajo en distintos conjuntos de datos de problemas de optimización superan a los alcanzados por los trabajos que modelan aplicando \textit{prompt engineering} a los modelos de lenguaje.
Otro aporte interesante de este trabajo es el análisis de la efectividad de ChatGPT-o1, un modelo “razonador”, en esta tarea. Aunque no se logra realizar un gran número de experimentos y comparaciones debido a la baja accesibilidad de la \textit{API} del modelo en ese momento, si se propone realizar un estudio de las capacidades de estos modelos “razonadores” en un futuro.

A pesar de que aplicar \textit{fine-tuning} sobre modelos de lenguaje de código abierto, para traducir descripciones en lenguaje natural a modelos de optimización, ha demostrado un rendimiento sobresaliente, esta aproximación presenta varias desventajas significativas que deben tenerse en cuenta.
Una de ellas es la escasez y el alto costo de los datos de entrenamiento. A diferencia de tareas lingüísticas con abundantes corpus públicos, los problemas de optimización completos (enunciado, variables, restricciones y soluciones de referencia) suelen existir en repositorios dispersos,
o dentro de entornos industriales confidenciales. Esta carencia de datos introduce riesgos de sobreajuste a dominios limitados (p. ej., solo logística o sólo programación lineal) y reduce la capacidad de generalización del
modelo. Además, el proceso de \textit{fine-tuning} sobre millones de parámetros exige recursos computacionales considerables que incrementan significativamente el costo monetario.

\subsection{Modelación Formal}
En los trabajos consultados se exponen diversas formas de modelar formalmente, o semi-formalmente un problema de optimización, sin embargo en muchos de ellos no se aborda con demasiado detalle que estructura siguen estas modelaciones o que características presentan.
A continuación se presenta una caracterización de las diferentes opciones de modelación encontradas en la literatura estudiada:

\begin{itemize}
    \item Modelación usando representaciones intermedias (IR) (\cite{ramamonjison2023nl4optcompetitionformulatingoptimization}, \cite{ning2023novelapproachautoformulationoptimization}, \cite{highlightingnamedentities}, \cite{ramamonjison2022augmentingoperationsresearchautoformulation}), esta representación tiene la ventaja de ser \textit{parseable}, faciltando la validación del modelo y su transformación a otras representaciones. Sin embargo, como se mencionó anteriormente, trabajos recientes no usan esta representación.
    \item Representación usando lenguajes de modelado como MiniZinc, MindOpt o CPMpy (\cite{tsouros2023holygrail20natural}, \cite{almonacid2023automaticoptimisationmodelgenerator}).
    \item Modelación matemática (\cite{ahmaditeshnizi2025optimus03usinglargelanguage}, \cite{bertsimas2024robustadaptiveoptimizationlarge}, \cite{huang2025orlmcustomizableframeworktraining}, \cite{zhang2024solvinggeneralnaturallanguagedescriptionoptimization}, \cite{li2023synthesizingmixedintegerlinearprogramming}, \cite{xiao2024chainofexperts}), esta representación formal es la más usada dentro de los trabajos consultados, aunque su estructura varía en dependecia de la metodología usada. En algunos casos se usa simplemente una plantilla con una estructura sencilla (Variables, Restricciones, Objetivo) para que el LLM rellene, en otros casos se estructura de forma un poco mas detallada utilizando  código \textit{MarkDown} o \textit{Latex} para representar las cláusulas (\cite{jiang2025llmopt}, \cite{ahmaditeshnizi2025optimus03usinglargelanguage}).
    \item Modelación usando formatos específicos como \textit{JSON} (\cite{thind2025optimaioptimizationnaturallanguage}, \cite{ahmaditeshnizi2023optimusoptimizationmodelingusing}), el uso formatos como \textit{JSON} permite estructurar la modelación de manera formal y organizada. De esta forma permite representar no solo la modelación matemática, sino también el contexto y características de cada cláusula y variable, así como los metadatos del problema.
\end{itemize}

Generalmente, cualquier problema de optimización se puede modelar matemáticamente usando variables, restricciones y objetivos. Sin embargo, en el trabajo de \cite{jiang2025llmopt} se presenta una formulación de cinco elementos: conjuntos, parámetros, variables, restricciones y objetivo.
En este estudio se afirma que el uso de esta re-presentación resulta en una formulación mas precisa del problema, favoreciendo la legibilidad y comprensión del modelo. Se demuestra además, que la formulación de cinco elementos es más facil de entender y generar por un LLM que la modelación matemática.
Esto se concluye al comparar el rendimiento de un modelo de lenguaje para modelar un conjunto de problemas de optimización alternando entre estas dos variantes.

\section{Enfoques de Solución}
Habiendo abordado en la sección anterior que técnicas y estrategias se usan para modelar un problema de optimización a partir de lenguaje natural, se pretende exponer en esta sección cómo encontrar una solución al problema de forma directa.
Se exploran dos caminos de solución fundamentales: por un lado, el uso de LLMs para generar el código y el modelo formal que herramientas externas o solvers se encargan de optimizar; y por otro, el uso del LLM como el propio motor de optimización, capaz de inferir la solución sin necesidad de intermediarios.

\subsection{Integración Modelos - Herramientas Externas}
En la literatura consultada, el enfoque más utlizado para resolver directamente un problema de optimización, a partir de su descripción en lenguaje natural fue una estrategia que consta de dos pasos.
Primero se modela el problema usando diferentes técnicas abordadas en la sección anterior, luego a partir de esa modelación formal se genera y ejecuta código específico, empleando herramientas o solucionadores (\textit{solvers}) externos.
Esta estrategia puede ilustrarse de forma general como se muestra en la Figura \ref{fig: pipeline}


\begin{figure}[h]
    \centering
    \makebox[\textwidth]{
        \includegraphics[width=1.2 \textwidth]{pipeline.png}
    }
    \caption{Estrategia general de solución}
    \label{fig: pipeline}
\end{figure}

En base a que las estrategias de modelado ya se abordaron en la sección anterior, esta subsección se centrará en analizar los enfoques empleados para resolver un problema de optimización a partir de una modelación formal.

Una estrategia fundamental, identificada en diversos trabajos de investigación, es el proceso de depuración o \textit{debugging} (\cite{ahmaditeshnizi2025optimus03usinglargelanguage}, \cite{zhang2024solvinggeneralnaturallanguagedescriptionoptimization}, \cite{jiang2025llmopt}, \cite{huang2025orlmcustomizableframeworktraining}, \cite{thind2025optimaioptimizationnaturallanguage}).
Una vez que los \textit{solvers} y herramientas externas ejecutan el código de modelado generado, es posible que estas lancen errores, debido a sintaxis incorrecta en el código o problemas ocurridos en tiempo de ejecución.
Estos errores se capturan y se utilizan como retroalimentación, permitiendo refinar y corregir el código generado inicialmente.
Esta estrategia ayuda a corregir alucionaciones producidas por los modelos de lenguaje en la generación de código, así como manejar situaciones inesperadas en la ejecución.

Otra técnica bastante empleada es el análisis cualitativo de los resultados. Dada la solución hallada por el \textit{solver} se le realiza una consulta a un modelo de lenguaje, donde se le pide analizar si los resultados obtenidos tienen sentido dado el problema inicial.
Esto permite capturar errores en la solución que no dependen de un código incorrecto, sino de un modelo mal traducido a código o mal generado. A partir de la retroalimentación del modelo es posible intentar corregir el problema, independientemente si es un problema del paso de modelación o del paso de ejecución.

Trabajos como \textit{OptimAI} (\cite{thind2025optimaioptimizationnaturallanguage}) incluyen además una etapa de planificación entre los pasos de modelación y generación-ejecución de código.
En esta etapa se realiza un análisis de las características del problema y los \textit{solvers} disponibles con el objetivo de maquetar distintas vias de solución, además de permitir escoger un \textit{solver} adecuado para el problema.
Además implementan un mecanismo de decisión que permite cambiar entre estrategias teniendo en cuenta cuantas iteraciones de depuración se han realizado.
Este trabajo, a diferencia de otros que solo se enfocan en resolver problemas de programación lineal (LP) o programación entera mixta (MILP), puede manejar un amplio rango de problemas combinando diferentes \textit{solver} y herramientas.

\subsection{LLMs como Optimizadores}
En el trabajo de~\cite{yang2024largelanguagemodelsoptimizers} se introduce \textit{Optimization by PROmpting} (OPRO), un enfoque que emplea los grandes modelos de lenguaje
como optimizadores. Esta metodología aprovecha tanto la capacidad de los LLM para procesar lenguaje natural como su habilidad para el aprendizaje en contexto, especialmente, para inferir
patrones a partir de ejemplos (\cite{mirchandani2023largelanguagemodelsgeneral}).
El objetivo es lograr que el modelo de lenguaje genere directamente candidatos a soluciones de un problema de optimización.
Para llevar a cabo este propósito se diseña un proceso iterativo, donde en cada ciclo el LLM recibe como entrada un \textit{meta-prompt} con dos informaciones claves:
la descripción del problema en lenguaje natural, y un conjunto de soluciones encontradas anteriormente.
Este conjunto de soluciones poseen un puntaje asociado, y están ordenadas de forma ascendente, facilitando al modelo de lenguaje seguir la trayectoria de optimización de las soluciones.
Una vez que el LLM propone una serie de soluciones nuevas, un módulo evaluador califica esas soluciones y las añade al \textit{meta-prompt} para la siguiente iteración.

La eficacia del método OPRO fue evaluada en dos problemas de optimización clásicos: la regresión lineal y el problema del viajante, o como se conoce en inglés: \textit{the traveling salesman problem} (TSP).
En instancias de pequeña escala, el enfoque obtiene resultados prometedores, demostrando así la capacidad de los LLMs para abordar funciones objetivo diversas utilizando únicamente prompts.
No obstante, el estudio también identifica limitaciones significativas. Entre ellas destacan la dificultad para escalar a problemas de mayor tamaño debido al límite de la ventana de contexto, y una menor eficacia al tratar con funciones objetivo complejas o grandes cantidades de variables,
lo que puede conducir al estancamiento en la búsqueda de soluciones de alta calidad.
Finalmente, se concluye que este enfoque aún no supera en rendimiento a los algoritmos y \textit{solvers} especializados existentes.

Otros trabajos como los publicados por~\cite{huang2024exploringtruepotentialevaluating} y \cite{guo2024optimizinglargelanguagemodels} también evaluan a los grandes modelos de lenguaje como optimizadores, aunque presentan pequeños cambios en su metodología con respecto a OPRO. Entre las modificaciones podemos mencionar la exploración de las capacidades del modelo de encontrar soluciones nuevas siguiendo estrategias como \textit{Grid Search}, \textit{Gradient Descent} o \textit{Hill Climbing}.
Ambos trabajos llegan a conclusiones similares a las alcanzadas por \cite{yang2024largelanguagemodelsoptimizers}, destacando el potencial de los LLMs para resolver eficientemente instancias pequeñas de problemas conocidos de optimización.
Sin embargo también plantean que su eficacia decrece ampliamente al escalar el tamaño y complejidad de los problemas, dificultando su aplicación en la práctica.

\section{Análisis General}
El estudio de la literatura evidencia un consenso claro en la utilidad de los Grandes Modelos de Lenguaje sobre otros métodos para la modelación de problemas de optimización.
Se identifican dos enfoques principales para entrenar a un LLM en la tarea de modelación, con un balance importante: el \textit{fine-tuning} ofrece mejor rendimiento, pero a expensas de un alto costo computacional y la dependencia de datos escasos; mientras que \textit{in-context learning} es más viable y generalizable, logrando alta eficacia mediante arquitecturas de agentes complejas y técnicas avanzadas como la reflexión.
Paralelamente, la estrategia de solución más robusta se centra en una arquitectura dual: el modelo de lenguaje se encarga del modelado, y solvers externos especializados ejecutan el código, utilizando mecanismos de retroalimentación y depuración para corregir los errores en tiempo de ejecución.
También es importante tener en cuenta que no se ha explorado completamente el potencial de los nuevos modelos “razonado-res” en esta tarea de solución y modelación de problemas de optimización, lo cual representa un tema relevante en el que indagar.


